{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q4: Neural Additive Models2 (7 Pts)\n",
    "Another way to make deep models more interpretable is by careful design of the architecture. One example of such a model is the Neural Additive Model (NAM), which is an instance of the class of Generalized Additive Models3 (GAM). Read the paper about NAMs, implement the model, and train it on the dataset (3 Pt). Like Q2-3, provide performance metrics on the test set. Utilize the interpretability of NAMs to visualize the feature importances (2 Pt). Conceptually, how does the model compare to Logistic Regression and MLPs (1 Pt)? Why are NAMs more interpretable than MLPs despite being based on non-linear neural networks (1 Pt)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Neural Additive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
